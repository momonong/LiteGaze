import tensorflow as tf
import numpy as np
import os
from models import build_student_v2
from data_utils import load_data, augment_image

# === âš™ï¸ è¨­å®šå€ ===
DATA_PATH = "data/mpiigaze_60x60.npz"  # è«‹ç¢ºèªæ‚¨çš„ npz è·¯å¾‘
BATCH_SIZE = 32
EPOCHS = 30
LEARNING_RATE = 1e-4
CLIPNORM = 1.0
NUM_BINS = 90
# è§’åº¦ç¯„åœ (Radians) -1.57 ~ 1.57 (ç´„ -90åº¦ ~ 90åº¦)
BIN_MIN = -1.57 
BIN_MAX = 1.57

def process_targets(image, label):
    """
    å°‡å–®ä¸€çš„ label (Pitch, Yaw) è½‰æ›æˆæ¨¡å‹éœ€è¦çš„ä¸‰ç¨®è¼¸å‡ºï¼š
    1. gaze_out: åŸæœ¬çš„é€£çºŒæ•¸å€¼ (ç”¨ä¾†ç®— MSE)
    2. pitch_logits: Pitch å±¬æ–¼å“ªä¸€å€‹ Bin (ç”¨ä¾†ç®—åˆ†é¡ Loss)
    3. yaw_logits: Yaw å±¬æ–¼å“ªä¸€å€‹ Bin (ç”¨ä¾†ç®—åˆ†é¡ Loss)
    """
    pitch = label[0]
    yaw = label[1]

    # å°‡é€£çºŒè§’åº¦æ˜ å°„åˆ° 0 ~ (NUM_BINS-1) çš„æ•´æ•¸ç´¢å¼•
    # Normalize to 0.0 ~ 1.0
    p_norm = (pitch - BIN_MIN) / (BIN_MAX - BIN_MIN)
    y_norm = (yaw - BIN_MIN) / (BIN_MAX - BIN_MIN)
    
    # Scale to index
    p_idx = tf.cast(p_norm * (NUM_BINS - 1), tf.int32)
    y_idx = tf.cast(y_norm * (NUM_BINS - 1), tf.int32)
    
    # é™åˆ¶ç¯„åœ (Clip) é¿å…è¶…å‡ºå»
    p_idx = tf.clip_by_value(p_idx, 0, NUM_BINS - 1)
    y_idx = tf.clip_by_value(y_idx, 0, NUM_BINS - 1)

    return image, {
        'gaze_out': label,     # å›æ­¸ä»»å‹™
        'pitch_logits': p_idx, # åˆ†é¡ä»»å‹™ (Pitch)
        'yaw_logits': y_idx    # åˆ†é¡ä»»å‹™ (Yaw)
    }

def main():
    # 1. è¼‰å…¥è³‡æ–™
    print("ğŸ“¥ Loading data...")
    if not os.path.exists(DATA_PATH):
        print(f"âŒ Error: æ‰¾ä¸åˆ° {DATA_PATH}ï¼Œè«‹æŠŠä¹‹å‰çš„ .npz æª”è¤‡è£½éä¾†ï¼")
        return

    images, labels = load_data(DATA_PATH)
    print(f"âœ… Data loaded: {images.shape}, {labels.shape}")

    # ç°¡å–®åˆ‡åˆ† Train/Val
    split_idx = int(len(images) * 0.9)
    train_imgs, val_imgs = images[:split_idx], images[split_idx:]
    train_lbls, val_lbls = labels[:split_idx], labels[split_idx:]

    # 2. å»ºç«‹ Pipeline
    # Train Set (åŠ å…¥ Augmentation + Target Processing)
    train_ds = tf.data.Dataset.from_tensor_slices((train_imgs, train_lbls))
    train_ds = train_ds.shuffle(1000)
    train_ds = train_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE) # å…ˆåšå½±åƒå¢å¼·
    train_ds = train_ds.map(process_targets, num_parallel_calls=tf.data.AUTOTUNE) # å†åšæ¨™ç±¤è½‰æ›
    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # Val Set (ä¸åš Augmentationï¼Œä½†è¦åš Target Processing)
    val_ds = tf.data.Dataset.from_tensor_slices((val_imgs, val_lbls))
    val_ds = val_ds.map(lambda x, y: (tf.image.resize(x, (60,60)), y)) # ç¢ºä¿å°ºå¯¸æ­£ç¢º
    val_ds = val_ds.map(process_targets, num_parallel_calls=tf.data.AUTOTUNE)
    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # 3. å»ºç«‹æ¨¡å‹
    print("ğŸ—ï¸ Building LiteGaze V2 Model...")
    model = build_student_v2(input_shape=(60, 60, 3))
    model.summary()

    # 4. ç·¨è­¯ (Compile)
    # L2CS æ ¸å¿ƒï¼šåŒæ™‚å„ªåŒ–åˆ†é¡æº–ç¢ºåº¦ (CrossEntropy) å’Œ å›æ­¸æº–ç¢ºåº¦ (MSE)
    losses = {
        'gaze_out': 'mse',
        'pitch_logits': 'sparse_categorical_crossentropy',
        'yaw_logits': 'sparse_categorical_crossentropy'
    }
    
    # æ¬Šé‡åˆ†é…ï¼šé€šå¸¸åˆ†é¡ Loss æ¯”è¼ƒå¤§ï¼Œçµ¦å®ƒ 1.0ï¼ŒMSE çµ¦å°ä¸€é»æˆ–ç›¸ç­‰
    loss_weights = {
        'gaze_out': 1.0,     # å›æ­¸æ¬Šé‡
        'pitch_logits': 1.0, # Pitch åˆ†é¡æ¬Šé‡
        'yaw_logits': 1.0    # Yaw åˆ†é¡æ¬Šé‡
    }

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=CLIPNORM),
        loss=losses,
        loss_weights=loss_weights,
        metrics={'gaze_out': 'mae'} # æˆ‘å€‘ä¸»è¦çœ‹ MAE (å¹³å‡çµ•å°èª¤å·®)
    )

    # 5. é–‹å§‹è¨“ç·´
    print("ğŸš€ Start Training...")
    callbacks = [
        # âœ… åŠ å…¥ mode='min'ï¼Œå‘Šè¨´å®ƒèª¤å·®è¶Šå°è¶Šå¥½
        tf.keras.callbacks.ModelCheckpoint(
            "litegaze_v2_best.h5", 
            save_best_only=True, 
            monitor='val_gaze_out_mae', 
            mode='min' 
        ),
        # âœ… é€™è£¡ä¹Ÿè¦åŠ 
        tf.keras.callbacks.EarlyStopping(
            patience=5, 
            monitor='val_gaze_out_mae', 
            restore_best_weights=True, 
            mode='min'
        ),
        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2, monitor='val_gaze_out_mae', mode='min')
    ]

    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=callbacks
    )

    # 6. è½‰å‡º TFLite
    print("ğŸ“¦ Exporting to TFLite...")
    # è¼‰å…¥æœ€å¥½çš„æ¬Šé‡
    model.load_weights("litegaze_v2_best.h5")
    
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT] # é è¨­é‡åŒ–
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
    
    tflite_model = converter.convert()
    
    with open('litegaze_v2.tflite', 'wb') as f:
        f.write(tflite_model)
    
    print("ğŸ‰ Done! Model saved to 'litegaze_v2.tflite'")

if __name__ == '__main__':
    main()