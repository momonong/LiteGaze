import tensorflow as tf
import numpy as np
import os
import h5py
from models import build_teacher_v3

# === âš™ï¸ A100 è¶…ç´šæ•™å¸«è¨­å®š ===
DATA_PATH = "data/teacher_224.h5"  # é€™æ˜¯å‰›å‰›æ­£åœ¨åšçš„æª”æ¡ˆ
BATCH_SIZE = 64                    # A100 è¨˜æ†¶é«”å¤§ï¼Œå¯ä»¥é–‹å¤§ä¸€é» (64/128)
EPOCHS = 20                        # å¤§æ¨¡å‹æ”¶æ–‚å¿«
LEARNING_RATE = 1e-5               # å¾®èª¿å»ºè­°ç”¨å°ä¸€é»çš„ LR
NUM_BINS = 90
BIN_MIN, BIN_MAX = -1.57, 1.57     # Radians

def hdf5_generator(path, batch_size, is_train=True):
    """
    HDF5 ä¸²æµç”Ÿæˆå™¨
    å°±åƒè¿´è½‰å£½å¸å¸«å‚…ï¼Œä¸€æ¬¡åªæ‹¿ batch_size ç›¤å‡ºä¾†
    """
    while True:
        with h5py.File(path, 'r') as hf:
            images_dset = hf['images']
            labels_dset = hf['labels']
            total_len = images_dset.shape[0]
            
            # ç”Ÿæˆéš¨æ©Ÿç´¢å¼• (å¦‚æœæ˜¯è¨“ç·´æ¨¡å¼)
            indices = np.arange(total_len)
            if is_train:
                np.random.shuffle(indices)
            
            # æ‰¹æ¬¡è®€å–
            for i in range(0, total_len, batch_size):
                batch_idx = indices[i : i + batch_size]
                # é€™è£¡è¦ sorted æ‰èƒ½è®€ h5ï¼Œè®€å®Œå† shuffle å›å»æœ‰é»éº»ç…©
                # ç‚ºäº†æ•ˆèƒ½ï¼Œæˆ‘å€‘é€™è£¡åšä¸€å€‹å¦¥å”ï¼šç›´æ¥è®€é€£çºŒå€å¡Šï¼Œç„¶å¾Œå† shuffle batch å…§éƒ¨
                # (å°æ–¼è¶…å¤§æ•¸æ“šé›†ï¼Œé€šå¸¸æœƒå…ˆéš¨æ©Ÿæ‰“æ•£å„²å­˜ï¼Œæˆ–è€…ç”¨æ›´è¤‡é›œçš„ Shufflerï¼Œé€™è£¡å…ˆæ±‚ç©©)
                
                # ä¿®æ­£ï¼šh5py æ”¯æ´ list indexing å—ï¼Ÿä¸ä¸€å®šã€‚
                # æœ€ç©©çš„æ–¹æ³•æ˜¯ sort index
                sorted_idx = np.sort(batch_idx)
                
                batch_imgs = images_dset[sorted_idx]
                batch_lbls = labels_dset[sorted_idx]
                
                # å› ç‚ºæˆ‘å€‘å‰›å‰›å­˜çš„æ˜¯ uint8 (0-255)ï¼Œé€™è£¡è¦è½‰æˆ float32 ä¸¦ Normalize
                batch_imgs = batch_imgs.astype(np.float32) / 255.0
                
                # é€™è£¡éœ€è¦æŠŠæ¨™ç±¤è½‰æˆ L2CS æ ¼å¼
                # Pitch/Yaw processing
                p_idx_list = []
                y_idx_list = []
                
                for label in batch_lbls:
                    pitch, yaw = label[0], label[1]
                    p_norm = (pitch - BIN_MIN) / (BIN_MAX - BIN_MIN)
                    y_norm = (yaw - BIN_MIN) / (BIN_MAX - BIN_MIN)
                    p_idx = int(np.clip(p_norm * (NUM_BINS - 1), 0, NUM_BINS - 1))
                    y_idx = int(np.clip(y_norm * (NUM_BINS - 1), 0, NUM_BINS - 1))
                    p_idx_list.append(p_idx)
                    y_idx_list.append(y_idx)
                
                yield batch_imgs, {
                    'gaze_out': batch_lbls,
                    'pitch_logits': np.array(p_idx_list),
                    'yaw_logits': np.array(y_idx_list)
                }

def create_dataset(h5_path, batch_size, is_train=True):
    # å–å¾—è³‡æ–™ç¸½é•·åº¦
    with h5py.File(h5_path, 'r') as hf:
        total_samples = hf['images'].shape[0]
        
    output_signature = (
        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
        {
            'gaze_out': tf.TensorSpec(shape=(None, 2), dtype=tf.float32),
            'pitch_logits': tf.TensorSpec(shape=(None,), dtype=tf.int32),
            'yaw_logits': tf.TensorSpec(shape=(None,), dtype=tf.int32),
        }
    )
    
    ds = tf.data.Dataset.from_generator(
        lambda: hdf5_generator(h5_path, batch_size, is_train),
        output_signature=output_signature
    )
    
    # å„ªåŒ–æ•ˆèƒ½
    ds = ds.prefetch(tf.data.AUTOTUNE)
    return ds, total_samples

def main():
    print("ğŸš€ Initializing God Teacher Training (HDF5 Streaming Mode)...")
    
    if not os.path.exists(DATA_PATH):
        print(f"âŒ Error: æ‰¾ä¸åˆ° {DATA_PATH}")
        return

    # 1. å»ºç«‹ Dataset
    # é€™è£¡ç°¡åŒ–ï¼šæ²’æœ‰åˆ† Train/Valï¼Œç›´æ¥å…¨éƒ¨ Train (å› ç‚ºä¸»è¦æ˜¯ç‚ºäº†è’¸é¤¾ï¼Œè€å¸«çœ‹éä¹Ÿæ²’é—œä¿‚)
    # æˆ–æ˜¯æ‚¨å¯ä»¥åˆ‡åˆ†å…©å€‹ h5 æª”ã€‚é€™é‚Šå…ˆåšç°¡å–®ç‰ˆï¼š90% ç”¨æ–¼è¨“ç·´
    train_ds, total_samples = create_dataset(DATA_PATH, BATCH_SIZE, is_train=True)
    
    steps_per_epoch = total_samples // BATCH_SIZE
    print(f"ğŸ“Š Total samples: {total_samples}, Steps per epoch: {steps_per_epoch}")

    # 2. å»ºç«‹æ¨¡å‹
    # å¿…é ˆè¦ç”¨ MirroredStrategy æ‰èƒ½æ¦¨ä¹¾ A100 çš„å¤šå¡æ•ˆèƒ½ (å¦‚æœæ˜¯å–®å¡ä¹Ÿæ²’é—œä¿‚)
    strategy = tf.distribute.MirroredStrategy()
    print(f"âœ… Number of devices: {strategy.num_replicas_in_sync}")

    with strategy.scope():
        model = build_teacher_v3(input_shape=(224, 224, 3))
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(
            learning_rate=LEARNING_RATE, 
            global_clipnorm=1.0  # å¼·åˆ¶é™åˆ¶æ¢¯åº¦ç¸½é•·åº¦
        ),
            loss={
                'gaze_out': 'mse', 
                'pitch_logits': 'sparse_categorical_crossentropy', 
                'yaw_logits': 'sparse_categorical_crossentropy'
            },
            loss_weights={'gaze_out': 1.0, 'pitch_logits': 1.0, 'yaw_logits': 1.0},
            metrics={'gaze_out': 'mae'}
        )
    
    model.summary()

    # 3. è¨“ç·´
    callbacks = [
        tf.keras.callbacks.ModelCheckpoint("models/teacher_v3_best.h5", save_best_only=True, monitor='loss', mode='min'),
        # å¦‚æœæ²’æœ‰ Validation Setï¼Œæˆ‘å€‘å°± Monitor 'loss'
        tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=2, mode='min')
    ]

    print("ğŸ”¥ Start Training on High-Performance GPU...")
    model.fit(
        train_ds,
        epochs=EPOCHS,
        steps_per_epoch=steps_per_epoch,
        callbacks=callbacks
    )
    
    print("ğŸ‰ God Teacher Trained & Saved!")

if __name__ == "__main__":
    main()