import tensorflow as tf
from tensorflow.keras import layers, models, losses, optimizers
import numpy as np
import h5py
import os
import sys  # <--- æ–°å¢žé€™è¡Œ

sys.path.append(os.getcwd()) 
# === å¼•å…¥æ‚¨çš„æ¨¡åž‹å»ºæ§‹å‡½å¼ ===
# é€™æ¨£å°±ä¸æœƒå ±éŒ¯äº†
from models import build_teacher_v3, build_student_v2

# === âš™ï¸ è¨­å®šå€ (Rapid Mode) ===
TEACHER_WEIGHTS_PATH = 'models/teacher_v3_best_5090.h5' # å‰›å‰›ç·´å¥½çš„è€å¸«æ¬Šé‡æª”å (è«‹ç¢ºèªæ‚¨çš„æª”å)
DATA_PATH = 'data/teacher_224.h5'      # ç¹¼çºŒç”¨é€™ä»½è³‡æ–™
BATCH_SIZE = 16                        # 5090 è·‘ 16 å¾ˆç©©
EPOCHS = 3                             # å­¸ç”Ÿæ¯”è¼ƒç¬¨ï¼Œçµ¦ä»– 3 è¼ª (ç´„ 3-4 å°æ™‚)
LR = 1e-4                              # å­¸ç”Ÿæ˜¯å¾žé ­ç·´ï¼Œå­¸ç¿’çŽ‡å¯ä»¥æ­£å¸¸é»ž
ALPHA = 0.5                            # 0.5 å­¸è€å¸«ï¼Œ0.5 å­¸æ¨™æº–ç­”æ¡ˆ
TEMPERATURE = 3.0                      # è’¸é¤¾æº«åº¦

# === æº–å‚™æ¨¡åž‹é¡žåˆ¥ (Distiller) ===
class DistillModel(models.Model):
    def __init__(self, student, teacher):
        super(DistillModel, self).__init__()
        self.student = student
        self.teacher = teacher

    def compile(self, optimizer, metrics, student_loss_fn, distill_loss_fn, alpha=0.1, temperature=3):
        super(DistillModel, self).compile(optimizer=optimizer, metrics=metrics)
        self.student_loss_fn = student_loss_fn
        self.distill_loss_fn = distill_loss_fn
        self.alpha = alpha
        self.temperature = temperature

    def train_step(self, data):
        x, y = data
        
        # 1. æº–å‚™è¼¸å…¥
        # è€å¸«çœ‹é«˜æ¸… RGB
        teacher_input = x 
        
        # å­¸ç”Ÿçœ‹ä½Žæ¸…ï¼Œä¸¦ä¸”è½‰æˆé»‘ç™½ï¼
        student_input_resize = tf.image.resize(x, (60, 60))
        student_input = tf.image.rgb_to_grayscale(student_input_resize)

        # 2. è€å¸«å…ˆçœ‹ (Training=False)
        teacher_pred = self.teacher(teacher_input, training=False)
        t_pitch_logits = teacher_pred[1]
        t_yaw_logits = teacher_pred[2]

        # 3. å­¸ç”Ÿå­¸ç¿’
        with tf.GradientTape() as tape:
            # é€™è£¡é¤µé€²åŽ»çš„ student_input ç¾åœ¨æ˜¯ (Batch, 60, 60, 1) äº†ï¼Œæ¨¡åž‹å°±ä¸æœƒå ±éŒ¯
            student_pred = self.student(student_input, training=True)
            
            s_gaze = student_pred[0]
            s_pitch_logits = student_pred[1]
            s_yaw_logits = student_pred[2]

            # Loss A: Gaze Vector MSE
            gaze_loss = self.student_loss_fn(y['gaze_out'], s_gaze)

            # Loss B: Distillation KL
            t_pitch_soft = tf.nn.softmax(t_pitch_logits / self.temperature)
            s_pitch_soft = tf.nn.softmax(s_pitch_logits / self.temperature)
            t_yaw_soft = tf.nn.softmax(t_yaw_logits / self.temperature)
            s_yaw_soft = tf.nn.softmax(s_yaw_logits / self.temperature)

            distill_loss_pitch = self.distill_loss_fn(t_pitch_soft, s_pitch_soft)
            distill_loss_yaw = self.distill_loss_fn(t_yaw_soft, s_yaw_soft)
            
            total_distill_loss = distill_loss_pitch + distill_loss_yaw

            # ç¸½æå¤±
            loss = (1 - self.alpha) * gaze_loss + (self.alpha) * total_distill_loss

        # 4. æ›´æ–°æ¬Šé‡
        trainable_vars = self.student.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        # 5. æ›´æ–° Metrics
        self.compiled_metrics.update_state(y['gaze_out'], s_gaze)
        
        return {
            "loss": loss, 
            "gaze_loss": gaze_loss, 
            "distill_loss": total_distill_loss
        }

# === è³‡æ–™ç”Ÿæˆå™¨ (è·Ÿä¹‹å‰ä¸€æ¨£) ===
def hdf5_generator(path, batch_size):
    while True:
        with h5py.File(path, 'r') as hf:
            images_dset = hf['images']
            labels_dset = hf['labels']
            total_len = images_dset.shape[0]
            indices = np.arange(total_len)
            np.random.shuffle(indices)
            
            for i in range(0, total_len, batch_size):
                batch_idx = np.sort(indices[i : i + batch_size])
                # è®€å– 224 åœ– (ä¹‹å¾Œåœ¨ Model å…§ç¸®æ”¾)
                batch_imgs = images_dset[batch_idx].astype(np.float32) / 255.0
                batch_lbls = labels_dset[batch_idx]
                
                yield batch_imgs, {'gaze_out': batch_lbls}

def main():
    print("ðŸš€ Loading Teacher Model weights...")
    # 1. å»ºç«‹è€å¸«ä¸¦è¼‰å…¥æ¬Šé‡
    teacher_model = build_teacher_v3()
    # ç¢ºä¿é€™è£¡çš„æª”åè·Ÿæ‚¨å‰›å‰›å­˜çš„ä¸€æ¨£ (å¯èƒ½æ˜¯ model.save é è¨­çš„ teacher_v3.h5 æˆ–å…¶ä»–)
    if os.path.exists(TEACHER_WEIGHTS_PATH):
        teacher_model.load_weights(TEACHER_WEIGHTS_PATH)
        print("âœ… Teacher weights loaded!")
    else:
        print(f"âŒ Error: Cannot find {TEACHER_WEIGHTS_PATH}")
        return
    
    # å‡çµè€å¸« (ä¸è¨“ç·´ä»–)
    teacher_model.trainable = False

    # 2. å»ºç«‹å…¨æ–°çš„å­¸ç”Ÿ
    print("ðŸ‘¶ Creating Student Model...")
    student_model = build_student_v2()

    # 3. æº–å‚™è³‡æ–™
    # ä½¿ç”¨è·Ÿå‰›å‰›ä¸€æ¨£çš„é‚è¼¯ï¼Œåªå–éƒ¨åˆ†è³‡æ–™åŠ é€Ÿ
    limit_samples = 42000 # è·Ÿå‰›å‰›ä¸€æ¨£ 10%
    
    output_signature = (
        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
        {'gaze_out': tf.TensorSpec(shape=(None, 2), dtype=tf.float32)}
    )
    
    ds = tf.data.Dataset.from_generator(
        lambda: hdf5_generator(DATA_PATH, BATCH_SIZE),
        output_signature=output_signature
    )
    ds = ds.take(limit_samples).prefetch(tf.data.AUTOTUNE)

    # 4. å»ºç«‹è’¸é¤¾å™¨
    distiller = DistillModel(student=student_model, teacher=teacher_model)
    
    distiller.compile(
        optimizer=optimizers.Adam(learning_rate=LR),
        metrics=[tf.keras.metrics.MeanAbsoluteError(name="mae")],
        student_loss_fn=losses.MeanSquaredError(),
        distill_loss_fn=losses.KLDivergence(),
        alpha=ALPHA,
        temperature=TEMPERATURE
    )

    # 5. é–‹å§‹è’¸é¤¾è¨“ç·´ï¼
    print(f"ðŸ”¥ Start Distillation for {EPOCHS} epochs...")
    distiller.fit(ds, epochs=EPOCHS, steps_per_epoch=limit_samples // BATCH_SIZE)

    # ... (å‰é¢çš„è¨“ç·´ fit ç¨‹å¼ç¢¼) ...

    # 6. æ­£ç¢ºå­˜æª”æµç¨‹
    print("ðŸ’¾ Saving Distilled Student...")
    
    # æ­¥é©Ÿ A: å…ˆå­˜æˆ Keras H5 æ ¼å¼ (é€™æ˜¯æœ€é‡è¦çš„ï¼Œæœ‰äº†é€™å€‹éš¨æ™‚å¯ä»¥è½‰ TFLite)
    # include_optimizer=False å¯ä»¥è®“æª”æ¡ˆå°ä¸€é»žï¼Œé æ¸¬æ™‚ä¸éœ€è¦å„ªåŒ–å™¨
    h5_path = "models/litegaze_distilled_final.h5"
    student_model.save(h5_path, include_optimizer=False)
    print(f"âœ… H5 model saved: {h5_path}")
    
    # æ­¥é©Ÿ B: æ‰‹å‹•è½‰æ›æˆ TFLite
    print("âš™ï¸ Converting to TFLite...")
    converter = tf.lite.TFLiteConverter.from_keras_model(student_model)
    
    # (é¸ç”¨) é‡å° TF operator çš„é¡å¤–è¨­å®šï¼Œé˜²æ­¢æŸäº›å±¤è½‰ä¸éŽåŽ»
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS, # Enable TensorFlow Lite ops.
        tf.lite.OpsSet.SELECT_TF_OPS    # Enable TensorFlow ops.
    ]
    
    tflite_model = converter.convert()
    
    tflite_path = 'models/litegaze_v2_distilled.tflite'
    with open(tflite_path, 'wb') as f:
        f.write(tflite_model)
    print(f"âœ… TFLite model generated: {tflite_path}")

if __name__ == "__main__":
    main()