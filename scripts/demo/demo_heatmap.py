import cv2
import mediapipe as mp
import numpy as np
import tensorflow as tf
from collections import deque

# === âš™ï¸ è¨­å®šå€ ===
MODEL_PATH = 'models/litegaze_v2_win.tflite'
INPUT_SIZE = (60, 60)

# ç†±åœ–è¨­å®š
HEATMAP_ALPHA = 0.6    # é€æ˜Žåº¦ (0.0~1.0)
SMOOTHING_FRAME = 5    # å¹³æ»‘åŒ–å¹€æ•¸ï¼Œæ•¸å€¼è¶Šå¤§è¶Šç©©å®šä½†å»¶é²è¶Šé«˜
GAZE_SENSITIVITY = 800 # éˆæ•åº¦ï¼Œæ•¸å€¼è¶Šå¤§ç†±é»žè·‘å¾—è¶Šé 

class GazeHeatmapDemo:
    def __init__(self):
        # è¼‰å…¥æ¨¡åž‹
        print("â³ Loading TFLite model...")
        self.interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)
        self.interpreter.allocate_tensors()
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        self.output_index = self.output_details[0]['index'] 

        # åˆå§‹åŒ– MediaPipe
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        # ç”¨æ–¼å¹³æ»‘åŒ–æ³¨è¦–é»žçš„ä½‡åˆ—
        self.gaze_history = deque(maxlen=SMOOTHING_FRAME)
        self.heatmap_canvas = None

    def get_gaze_point(self, pitch, yaw, img_h, img_w):
        """å°‡ Pitch/Yaw è§’åº¦è½‰æ›ç‚ºèž¢å¹•ä¸Šçš„ç²—ç•¥ (x, y) åæ¨™"""
        # å‡è¨­ç›¸æ©Ÿåœ¨èž¢å¹•ä¸­å¿ƒä¸Šæ–¹ï¼Œç°¡å–®ç·šæ€§æ˜ å°„
        # Yaw (å·¦å³) -> X è»¸, Pitch (ä¸Šä¸‹) -> Y è»¸
        # è² è™Ÿå¯èƒ½éœ€è¦æ ¹æ“šå¯¦éš›é«”é©—å¾®èª¿
        dx = -np.sin(yaw) * GAZE_SENSITIVITY
        dy = np.sin(pitch) * GAZE_SENSITIVITY
        
        center_x, center_y = img_w // 2, img_h // 2
        gaze_x = int(center_x + dx)
        gaze_y = int(center_y + dy)
        
        return gaze_x, gaze_y

    def draw_heatmap(self, image, gaze_point):
        h, w, _ = image.shape
        if self.heatmap_canvas is None:
            self.heatmap_canvas = np.zeros((h, w), dtype=np.float32)

        # 1. åœ¨ç•«å¸ƒä¸Šç¹ªè£½ä¸€å€‹æ–°çš„ç†±é»ž (é«˜æ–¯åˆ†ä½ˆ)
        gx, gy = gaze_point
        # ç¢ºä¿åæ¨™åœ¨åœ–åƒç¯„åœå…§ï¼Œä¸¦ç•™é‚Šç•Œçµ¦é«˜æ–¯æ¨¡ç³Š
        gx = np.clip(gx, 50, w - 50)
        gy = np.clip(gy, 50, h - 50)
        
        # å‰µå»ºä¸€å€‹å±€éƒ¨çš„é«˜æ–¯é®ç½©
        kernel_size = 201 # ç†±é»žå¤§å°
        sigma = 50        # ç†±é»žæ“´æ•£ç¨‹åº¦
        kernel = cv2.getGaussianKernel(kernel_size, sigma)
        kernel = kernel * kernel.T
        # Normalize åˆ° 0~1 ä¸¦å¢žå¼·å¼·åº¦
        kernel = kernel / kernel.max()
        
        # å°‡ç†±é»žç–ŠåŠ åˆ°ç•¶å‰ä½ç½®
        x1, y1 = gx - kernel_size // 2, gy - kernel_size // 2
        x2, y2 = x1 + kernel_size, y1 + kernel_size
        self.heatmap_canvas[y1:y2, x1:x2] = np.maximum(self.heatmap_canvas[y1:y2, x1:x2], kernel)

        # 2. è®“èˆŠçš„ç†±åº¦æ…¢æ…¢æ¶ˆé€€ (Decay)
        self.heatmap_canvas *= 0.92

        # 3. ç”¢ç”Ÿå½©è‰²ç†±åœ–
        heatmap_img = (self.heatmap_canvas * 255).astype(np.uint8)
        heatmap_color = cv2.applyColorMap(heatmap_img, cv2.COLORMAP_JET)
        
        # å°‡é»‘è‰²èƒŒæ™¯è®Šé€æ˜Ž
        mask = heatmap_img > 10
        overlay = image.copy()
        overlay[mask] = cv2.addWeighted(image[mask], 1 - HEATMAP_ALPHA, heatmap_color[mask], HEATMAP_ALPHA, 0)
        
        return overlay

    def run(self):
        cap = cv2.VideoCapture(0)
        print("ðŸš€ Starting Heatmap Demo... Look around!")
        
        while cap.isOpened():
            success, image = cap.read()
            if not success: break
            
            image = cv2.flip(image, 1) # é¡åƒ
            h, w, _ = image.shape
            
            # è™•ç†å½±åƒ
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb_image)

            current_gaze = None

            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    # æŠ“è‡‰èˆ‡è£åˆ‡ (èˆ‡ä¹‹å‰ç›¸åŒ)
                    x_coords = [lm.x for lm in face_landmarks.landmark]
                    y_coords = [lm.y for lm in face_landmarks.landmark]
                    x_min, x_max = int(min(x_coords)*w), int(max(x_coords)*w)
                    y_min, y_max = int(min(y_coords)*h), int(max(y_coords)*h)
                    pad = 30
                    x_min, y_min = max(0, x_min-pad), max(0, y_min-pad)
                    x_max, y_max = min(w, x_max+pad), min(h, y_max+pad)
                    
                    face_img = image[y_min:y_max, x_min:x_max]
                    if face_img.size == 0: continue

                    # æŽ¨è«–
                    input_img = cv2.resize(face_img, INPUT_SIZE)
                    input_data = input_img.astype(np.float32) / 255.0
                    input_data = np.expand_dims(input_data, axis=0)
                    
                    self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
                    self.interpreter.invoke()
                    pred = self.interpreter.get_tensor(self.output_index)[0]
                    
                    # è¨ˆç®—æ³¨è¦–é»ž
                    gaze_point = self.get_gaze_point(pred[0], pred[1], h, w)
                    self.gaze_history.append(gaze_point)
                    
                    # å¹³æ»‘åŒ–
                    avg_x = int(np.mean([p[0] for p in self.gaze_history]))
                    avg_y = int(np.mean([p[1] for p in self.gaze_history]))
                    current_gaze = (avg_x, avg_y)

            # ç¹ªè£½ç†±åœ– (å¦‚æžœæ²’æœ‰åµæ¸¬åˆ°è‡‰ï¼Œç†±åœ–æœƒæ…¢æ…¢æ¶ˆé€€)
            if current_gaze:
                output_image = self.draw_heatmap(image, current_gaze)
            elif self.heatmap_canvas is not None:
                 # æ²’æœ‰äººæ™‚ï¼Œè®“ç†±åœ–æŒçºŒæ¶ˆé€€
                 self.heatmap_canvas *= 0.9
                 heatmap_img = (self.heatmap_canvas * 255).astype(np.uint8)
                 heatmap_color = cv2.applyColorMap(heatmap_img, cv2.COLORMAP_JET)
                 mask = heatmap_img > 10
                 output_image = image.copy()
                 output_image[mask] = cv2.addWeighted(image[mask], 1 - HEATMAP_ALPHA, heatmap_color[mask], HEATMAP_ALPHA, 0)
            else:
                output_image = image

            cv2.imshow('LiteGaze V2 - Heatmap Visualization', output_image)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    demo = GazeHeatmapDemo()
    demo.run()