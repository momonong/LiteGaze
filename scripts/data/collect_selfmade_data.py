import torch
import cv2
import os
import numpy as np
from l2cs import Pipeline, render
import sys
import time

# ================= âš™ï¸ è¨­å®š =================
OUTPUT_DIR = 'data/selfmade_sisi'  # é€™æ˜¯æˆ‘å€‘çš„çµ‚æ¥µè³‡æ–™é›†
MODEL_PATH = 'models/L2CSNet_gaze360.pkl'
DEVICE = torch.device('cuda')
TARGET_COUNT = 3000  # ç›®æ¨™æ”¶é›† 3000 å¼µ
# =======================================

def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    print(f"ğŸš€ Loading Teacher Pipeline...")
    # é€™æ˜¯ç‚ºäº†ç¢ºä¿ã€Œè£åˆ‡é‚è¼¯ã€è·Ÿè€å¸«ä¸€æ¨¡ä¸€æ¨£
    gaze_pipeline = Pipeline(
        weights=MODEL_PATH, arch='ResNet50', device=DEVICE
    )

    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    print("\nğŸ® ã€å®Œç¾è³‡æ–™æ¡é›†æ¨¡å¼ã€‘")
    print("1. è«‹æŒ‰ [SPACE] é–‹å§‹/æš«åœ éŒ„è£½ã€‚")
    print("2. è«‹åšå„ç¨®å‹•ä½œï¼šè½‰é ­ã€æŠ¬é ­ã€ä½é ­ã€é è¿‘ã€é é›¢ã€‚")
    print("3. çœ¼ç›è«‹ç›¯è‘—è¢å¹•ä¸Šçš„ä¸åŒä½ç½®ï¼Œæˆ–è€…è·Ÿè‘—æ‰‹æŒ‡å‹•ã€‚")
    print("âš ï¸ åªæœ‰ç•¶ç¶ è‰²ç®­é ­æº–ç¢ºæ™‚ï¼Œæ‰è®“å®ƒéŒ„è£½ï¼")
    
    count = 0
    recording = False
    
    while True:
        ret, frame = cap.read()
        if not ret: break
        
        # 1. è®“è€å¸«çœ‹
        # æˆ‘å€‘éœ€è¦ä¿®æ”¹ pipeline è®“å®ƒå›å‚³ logits å—ï¼Ÿ
        # å…¶å¯¦ä¸ç”¨ï¼Œæˆ‘å€‘ç›´æ¥å­˜åœ–ï¼Œè¨“ç·´æ™‚å†è®“è€å¸«å³æ™‚ç®— Logits å°±å¥½
        # é€™æ¨£å¯ä»¥çœç¡¬ç¢Ÿç©ºé–“ï¼Œè€Œä¸”å¯ä»¥åš Data Augmentation
        
        # é€™è£¡æˆ‘å€‘åªç”¨ pipeline ä¾†å–å¾— "BBox" ä»¥ä¾¿è£åˆ‡
        try:
            results = gaze_pipeline.step(frame)
        except: continue

        frame_vis = render(frame.copy(), results)
        
        # 2. è£åˆ‡é‚è¼¯ (é€™æ˜¯é—œéµï¼å¿…é ˆè·Ÿ Teacher ä¸€è‡´)
        if results.bboxes is not None and len(results.bboxes) > 0:
            bbox = results.bboxes[0]
            x_min, y_min, x_max, y_max = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])
            
            # å®‰å…¨é‚Šç•Œ
            h, w, _ = frame.shape
            x_min, y_min = max(0, x_min), max(0, y_min)
            x_max, y_max = min(w, x_max), min(h, y_max)
            
            # å–å¾—è£åˆ‡åœ–
            face_img = frame[y_min:y_max, x_min:x_max]
            
            if face_img.size > 0:
                if recording:
                    # å­˜æª”
                    filename = f"{OUTPUT_DIR}/img_{count:05d}.jpg"
                    cv2.imwrite(filename, face_img)
                    count += 1
                    
                    # éŒ„å½±æŒ‡ç¤ºç‡ˆ (ç´…é»)
                    cv2.circle(frame_vis, (50, 50), 20, (0, 0, 255), -1)
                    cv2.putText(frame_vis, "REC", (80, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        # UI
        cv2.putText(frame_vis, f"Count: {count}/{TARGET_COUNT}", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        if not recording:
            cv2.putText(frame_vis, "Press SPACE to Record", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            
        cv2.imshow("Perfect Dataset Collector", frame_vis)
        
        key = cv2.waitKey(1) & 0xFF
        if key == 32: # SPACE
            recording = not recording
        elif key == ord('q'):
            break
        
        if count >= TARGET_COUNT:
            print("âœ… æ”¶é›†å®Œæˆï¼")
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()