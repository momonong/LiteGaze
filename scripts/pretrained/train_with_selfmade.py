import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import glob
import os
import cv2
import numpy as np
from PIL import Image

# ================= âš™ï¸ æ¥µé€Ÿè¨­å®š =================
DATA_DIR = 'data/selfmade_combined'
TEACHER_PATH = 'models/L2CSNet_gaze360.pkl'
STUDENT_SAVE_PATH = 'models/student_mobilenet_3people_9k.pth'

DEVICE = torch.device('cuda')

# ğŸ”¥ 5090 å°ˆå±¬å„ªåŒ–åƒæ•¸
BATCH_SIZE = 512        # ç›´æ¥é–‹ 256 æˆ– 512 (MobileNet å¾ˆå°ï¼Œæ”¾å¿ƒé–‹)
EPOCHS = 50             # æ—¢ç„¶è·‘å¾—å¿«äº†ï¼Œå°±ç·´æ»¿ 50 è¼ªï¼Œè®“å®ƒå¾¹åº•å­¸æœƒ
LR = 1e-3               # Batch è®Šå¤§ï¼Œå­¸ç¿’ç‡é€šå¸¸ä¹Ÿå¯ä»¥ç¨å¾®èª¿å¤§ä¸€é»é»
TEMP = 5.0
NUM_WORKERS = 8         # é–‹ 8 å€‹ CPU æ ¸å¿ƒå¹«å¿™è®€åœ–
# ==========================================

# Teacher Definition
class L2CS_ResNet50(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_ResNet50, self).__init__()
        self.model = models.resnet50(weights=None)
        self.model.fc = nn.Linear(2048, num_bins * 2)
    def forward(self, x):
        x = self.model(x)
        return x[:, :90], x[:, 90:]

# Student Definition
class L2CS_MobileNetV3(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_MobileNetV3, self).__init__()
        # è¼‰å…¥ ImageNet é è¨“ç·´æ¬Šé‡ (é€™å°é˜²æ­¢éæ“¬åˆå¾ˆæœ‰å¹«åŠ©)
        self.backbone = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)
        in_features = self.backbone.classifier[3].in_features
        self.backbone.classifier[3] = nn.Linear(in_features, num_bins * 2)
    def forward(self, x):
        x = self.backbone(x)
        return x[:, :90], x[:, 90:]

class PerfectDataset(Dataset):
    def __init__(self, root):
        self.files = glob.glob(os.path.join(root, "*.jpg"))
        print(f"ğŸ“Š è¼‰å…¥è³‡æ–™: {len(self.files)} å¼µ")
        
        # ğŸ”¥ å¼·åŠ›æ•¸æ“šå¢å¼·ï¼šé˜²æ­¢éæ“¬åˆåˆ°ä½ çš„å€‹äººç‰¹å¾µ
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            # éš¨æ©Ÿæ”¹è®Šäº®åº¦ã€å°æ¯”ã€é£½å’Œåº¦ (è®“å®ƒèªä¸å‡ºæ˜¯åŒä¸€å€‹æˆ¿é–“/å…‰ç·š)
            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
            # éš¨æ©Ÿç°éš
            transforms.RandomGrayscale(p=0.1),
            # éš¨æ©Ÿæ¨¡ç³Š (æ¨¡æ“¬å‹•æ…‹æ¨¡ç³Š)
            transforms.RandomApply([transforms.GaussianBlur(3)], p=0.1),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def __len__(self): return len(self.files)
    def __getitem__(self, i):
        try:
            img = Image.open(self.files[i]).convert('RGB')
            return self.transform(img)
        except: return torch.zeros(3, 224, 224)

def distillation_loss(student_logits, teacher_logits, T):
    soft_targets = nn.functional.softmax(teacher_logits / T, dim=1)
    soft_prob = nn.functional.log_softmax(student_logits / T, dim=1)
    return nn.KLDivLoss(reduction='batchmean')(soft_prob, soft_targets) * (T**2)

def main():
    print("ğŸš€ å•Ÿå‹•å®Œç¾è’¸é¤¾ç¨‹åº...")
    
    # 1. Teacher
    teacher = L2CS_ResNet50().to(DEVICE)
    ckpt = torch.load(TEACHER_PATH, map_location=DEVICE)
    state = {}
    for k, v in ckpt.items():
        if 'fc_pitch' in k or 'fc_yaw' in k: continue
        nk = 'model.'+k if not k.startswith('model.') else k
        state[nk] = v
    if 'fc_pitch_gaze.weight' in ckpt:
        state['model.fc.weight'] = torch.cat((ckpt['fc_pitch_gaze.weight'], ckpt['fc_yaw_gaze.weight']), 0)
        state['model.fc.bias'] = torch.cat((ckpt['fc_pitch_gaze.bias'], ckpt['fc_yaw_gaze.bias']), 0)
    teacher.load_state_dict(state, strict=False)
    teacher.eval()
    
    # 2. Student
    student = L2CS_MobileNetV3().to(DEVICE)
    student.train()
    
    dataset = PerfectDataset(DATA_DIR)
    dataloader = DataLoader(
        dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=True,
        num_workers=NUM_WORKERS,      # å¤šå·¥è®€åœ–
        pin_memory=True,              # åŠ é€Ÿå‚³è¼¸
        persistent_workers=True,      # è®“å·¥äººå¾…å‘½ï¼Œä¸è¦ä¸€ç›´é‡å•Ÿ
        prefetch_factor=4             # æ¯å€‹å·¥äººé å…ˆå¤šè®€ 4 å€‹ Batch
    )
    optimizer = optim.Adam(student.parameters(), lr=LR)
    
    print("ğŸ”¥ é–‹å§‹è¨“ç·´...")
    
    for epoch in range(EPOCHS):
        total_loss = 0
        for images in dataloader:
            images = images.to(DEVICE)
            
            # Teacher ç”¢ç”Ÿ Logits
            with torch.no_grad():
                tp, ty = teacher(images)
            
            # Student ç”¢ç”Ÿ Logits
            sp, sy = student(images)
            
            loss = distillation_loss(sp, tp, TEMP) + distillation_loss(sy, ty, TEMP)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            
        print(f"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss/len(dataloader):.4f}")
        
    torch.save(student.state_dict(), STUDENT_SAVE_PATH)
    print(f"âœ… æ¨¡å‹å·²å„²å­˜: {STUDENT_SAVE_PATH}")

if __name__ == '__main__':
    main()