import torch
import torch.nn as nn
from torchvision import transforms, models
import os
import glob
from PIL import Image
import numpy as np

# ================= è¨­å®š =================
DATA_DIR = 'data/official_calibration' # è«‹ç¢ºèªè·Ÿæ¡é›†æ™‚çš„è·¯å¾‘ä¸€è‡´
TEACHER_PATH = 'models/L2CSNet_gaze360.pkl'
# =======================================

class L2CS_ResNet50(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_ResNet50, self).__init__()
        self.model = models.resnet50(weights=None)
        self.model.fc = nn.Linear(2048, num_bins * 2)
    def forward(self, x):
        x = self.model(x)
        return x[:, :90], x[:, 90:]

def compute_gaze(logits):
    softmax = nn.Softmax(dim=1)
    prob = softmax(logits)
    idx = torch.arange(90, dtype=torch.float32).to(logits.device)
    gaze = torch.sum(prob * idx, dim=1) * 4 - 180
    return gaze.item()

def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Loading Teacher on {device}...")
    
    # è¼‰å…¥è€å¸«æ¨¡å‹
    teacher = L2CS_ResNet50().to(device)
    ckpt = torch.load(TEACHER_PATH, map_location=device)
    state = {}
    for k, v in ckpt.items():
        if 'fc_pitch' in k or 'fc_yaw' in k: continue
        nk = 'model.'+k if not k.startswith('model.') else k
        state[nk] = v
    if 'fc_pitch_gaze.weight' in ckpt:
        state['model.fc.weight'] = torch.cat((ckpt['fc_pitch_gaze.weight'], ckpt['fc_yaw_gaze.weight']), 0)
        state['model.fc.bias'] = torch.cat((ckpt['fc_pitch_gaze.bias'], ckpt['fc_yaw_gaze.bias']), 0)
    teacher.load_state_dict(state, strict=False)
    teacher.eval()
    
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # æº–å‚™çµ±è¨ˆ
    actions = {0: "UP", 1: "DOWN", 2: "LEFT", 3: "RIGHT", 4: "CENTER"}
    stats = {k: {'pitch': [], 'yaw': []} for k in actions.keys()}
    
    files = glob.glob(os.path.join(DATA_DIR, "*.jpg"))
    print(f"ğŸ“‚ Found {len(files)} images. Analyzing...")
    
    for f in files:
        filename = os.path.basename(f)
        try:
            # æª”åæ ¼å¼ act0_0001.jpg
            act_idx = int(filename.split('_')[0].replace('act', ''))
        except: continue
        
        img = Image.open(f).convert('RGB')
        inp = transform(img).unsqueeze(0).to(device)
        
        with torch.no_grad():
            tp, ty = teacher(inp)
            p_val = compute_gaze(tp)
            y_val = compute_gaze(ty)
            
            stats[act_idx]['pitch'].append(p_val)
            stats[act_idx]['yaw'].append(y_val)
            
    print("\n" + "="*50)
    print(f"{'ACTION':<10} | {'AVG PITCH':<15} | {'AVG YAW':<15} | {'STATUS'}")
    print("="*50)
    
    # é¡¯ç¤ºçµæœ
    for k, name in actions.items():
        if len(stats[k]['pitch']) == 0:
            print(f"{name:<10} | {'No Data':<15} | {'No Data':<15}")
            continue
            
        avg_p = np.mean(stats[k]['pitch'])
        avg_y = np.mean(stats[k]['yaw'])
        
        # ç°¡å–®åˆ¤å®šç‹€æ…‹
        status = "âœ… OK"
        if name == "UP" and avg_p > -5: status = "âš ï¸ Weak (Not high enough)" # å‡è¨­è² æ˜¯ä¸Š
        if name == "DOWN" and avg_p < 5: status = "âš ï¸ Weak (Not low enough)"
        
        print(f"{name:<10} | {avg_p:>10.2f}Â°    | {avg_y:>10.2f}Â°    |")

    print("="*50)
    print("ğŸ’¡ åˆ¤æ–·æ¨™æº–ï¼š")
    print("1. UP çš„ Pitch æ‡‰è©²è¦æ˜¯ è² æ•¸ (ä¾‹å¦‚ -15 ~ -30)")
    print("2. DOWN çš„ Pitch æ‡‰è©²è¦æ˜¯ æ­£æ•¸ (ä¾‹å¦‚ +10 ~ +30)")
    print("   (æˆ–è€…åéä¾†ï¼Œé‡é»æ˜¯å…©å€‹æ•¸å€¼è¦å·®å¾ˆé ï¼)")
    print("3. LEFT å’Œ RIGHT çš„ Yaw ä¹Ÿè¦å·®å¾ˆé ã€‚")

if __name__ == "__main__":
    main()