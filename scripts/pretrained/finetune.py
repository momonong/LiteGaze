import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import glob
from PIL import Image

# ================= âš™ï¸ è¨­å®šå€ =================
# æŒ‡å‘å‰›å‰›é‚£å€‹æ•¸æ“šå¾ˆæ¼‚äº®çš„è³‡æ–™å¤¾
DATA_DIR = 'data/official_calibration' 
# è€å¸«æ¨¡å‹ (ç¶­æŒä¸è®Š)
TEACHER_PATH = 'models/L2CSNet_gaze360.pkl'
# é€™æ˜¯æˆ‘å€‘è¦æ‹¯æ•‘çš„å­¸ç”Ÿæ¨¡å‹ (è¼‰å…¥ä½ åŸæœ¬æœ€å¥½çš„é‚£å€‹ production)
STUDENT_LOAD_PATH = 'models/student_mobilenet_production.pth'
# é€™æ˜¯æœ€çµ‚æˆå“
STUDENT_SAVE_PATH = 'models/student_mobilenet_final_fix.pth'

BATCH_SIZE = 16  # å° Batch è®“å®ƒå­¸å¾—æ›´ç´°
EPOCHS = 20      # 20 è¼ªæš´åŠ›çŸ¯æ­£
LR = 0.001       # è¼ƒå¤§çš„å­¸ç¿’ç‡ (1e-3)
# ============================================

class L2CS_ResNet50(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_ResNet50, self).__init__()
        self.model = models.resnet50(weights=None)
        self.model.fc = nn.Linear(2048, num_bins * 2)
    def forward(self, x):
        x = self.model(x)
        return x[:, :90], x[:, 90:]

class L2CS_MobileNetV3(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_MobileNetV3, self).__init__()
        self.backbone = models.mobilenet_v3_large(weights=None)
        in_features = self.backbone.classifier[3].in_features
        self.backbone.classifier[3] = nn.Linear(in_features, num_bins * 2)
    def forward(self, x):
        x = self.backbone(x)
        return x[:, :90], x[:, 90:]

class SimpleDataset(Dataset):
    def __init__(self, root):
        self.files = glob.glob(os.path.join(root, "*.jpg"))
        # âš ï¸ é—œéµï¼šé€™è£¡ä¸åšä»»ä½• ColorJitterï¼Œæˆ‘å€‘è¦å®ƒæ­»è¨˜ç¡¬èƒŒä½ çš„ç’°å¢ƒ
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    def __len__(self): return len(self.files)
    def __getitem__(self, i):
        try:
            img = Image.open(self.files[i]).convert('RGB')
            return self.transform(img)
        except: return torch.zeros(3, 224, 224)

def main():
    device = torch.device('cuda')
    print("ğŸš€ å•Ÿå‹•æœ€çµ‚å¾®èª¿ (Final Finetune)...")

    # 1. è¼‰å…¥è€å¸«
    teacher = L2CS_ResNet50().to(device)
    ckpt = torch.load(TEACHER_PATH, map_location=device)
    state = {}
    for k, v in ckpt.items():
        if 'fc_pitch' in k or 'fc_yaw' in k: continue
        nk = 'model.'+k if not k.startswith('model.') else k
        state[nk] = v
    if 'fc_pitch_gaze.weight' in ckpt:
        state['model.fc.weight'] = torch.cat((ckpt['fc_pitch_gaze.weight'], ckpt['fc_yaw_gaze.weight']), 0)
        state['model.fc.bias'] = torch.cat((ckpt['fc_pitch_gaze.bias'], ckpt['fc_yaw_gaze.bias']), 0)
    teacher.load_state_dict(state, strict=False)
    teacher.eval()

    # 2. è¼‰å…¥å­¸ç”Ÿ
    print(f"ğŸ“¥ è¼‰å…¥å­¸ç”Ÿ: {STUDENT_LOAD_PATH}")
    student = L2CS_MobileNetV3().to(device)
    try:
        student.load_state_dict(torch.load(STUDENT_LOAD_PATH, map_location=device))
    except:
        print("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°èˆŠå­¸ç”Ÿæ¨¡å‹ï¼Œå°‡å¾é ­é–‹å§‹è¨“ç·´ (é€™ä¹Ÿæ²’å•é¡Œ)")
        # å¦‚æœæ‰¾ä¸åˆ°èˆŠçš„ï¼Œå°±è®“å®ƒç”¨ ImageNet æ¬Šé‡é‡æ–°å­¸é€™ 500 å¼µ
        student.backbone = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)
        in_features = student.backbone.classifier[3].in_features
        student.backbone.classifier[3] = nn.Linear(in_features, 180)
        student.to(device)
        
    student.train()
    
    # 3. æº–å‚™è¨“ç·´
    dataset = SimpleDataset(DATA_DIR)
    if len(dataset) == 0:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è¨“ç·´åœ–ç‰‡ï¼è«‹æª¢æŸ¥è·¯å¾‘ã€‚")
        return
    print(f"ğŸ“Š è¨“ç·´è³‡æ–™: {len(dataset)} å¼µ (é«˜å“è³ªå®˜æ–¹èªè­‰åœ–)")

    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
    optimizer = optim.Adam(student.parameters(), lr=LR)
    
    # 4. é–‹å§‹è¨“ç·´
    print("ğŸ”¥ é–‹å§‹è¨“ç·´...")
    for epoch in range(EPOCHS):
        total_loss = 0
        for imgs in dataloader:
            imgs = imgs.to(device)
            
            with torch.no_grad():
                tp, ty = teacher(imgs)
            
            sp, sy = student(imgs)
            
            # ä½¿ç”¨ MSE å¼·åŠ›çŸ¯æ­£
            loss = nn.MSELoss()(sp, tp) + nn.MSELoss()(sy, ty)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            
        print(f"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss/len(dataloader):.4f}")

    # 5. å­˜æª”
    torch.save(student.state_dict(), STUDENT_SAVE_PATH)
    print(f"\nâœ…âœ…âœ… æœ€çµ‚æ¨¡å‹å·²å„²å­˜: {STUDENT_SAVE_PATH}")
    print("ğŸ‘‰ ä¸‹ä¸€æ­¥ï¼šè«‹ä½¿ç”¨ demo_final_stable.py è¼‰å…¥é€™å€‹æ–°æ¨¡å‹é€²è¡Œæ¸¬è©¦ï¼")

if __name__ == "__main__":
    main()