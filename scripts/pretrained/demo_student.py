import torch
import torch.nn as nn
from torchvision import transforms, models
import cv2
import numpy as np
import time
from math import cos, sin
import os

# ================= ‚öôÔ∏è Ë®≠ÂÆöÂçÄ =================
MODEL_PATH = 'models/student_mobilenet_v3.pth'
INPUT_SIZE = 224
# ============================================

# ÂÆöÁæ©Â≠∏ÁîüÊ®°ÂûãÁµêÊßã
class L2CS_MobileNetV3(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_MobileNetV3, self).__init__()
        self.numOfLabels = num_bins
        self.backbone = models.mobilenet_v3_large(weights=None)
        in_features = self.backbone.classifier[3].in_features
        self.backbone.classifier[3] = nn.Linear(in_features, num_bins * 2)

    def forward(self, x):
        x = self.backbone(x)
        pitch = x[:, :self.numOfLabels]
        yaw = x[:, self.numOfLabels:]
        return pitch, yaw

def draw_gaze(image, pitch, yaw, center_x, center_y, face_width):
    # ÁÆ≠È†≠Èï∑Â∫¶Ë®≠ÁÇ∫ËáâÂØ¨ÁöÑ‰∏ÄÂçä
    length = face_width / 2.0
    
    dx = -length * sin(yaw) * cos(pitch)
    dy = -length * sin(pitch)
    
    # Áï´ÁÆ≠È†≠
    cv2.arrowedLine(image, (int(center_x), int(center_y)), 
                   (int(center_x + dx), int(center_y + dy)), 
                   (0, 0, 255), 4, cv2.LINE_AA, tipLength=0.2)

def softmax_temperature(tensor, temperature):
    result = torch.exp(tensor / temperature)
    result = torch.div(result, torch.sum(result, 1).unsqueeze(1).expand_as(result))
    return result

def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üöÄ Loading Student Model on {device}...")

    # 1. ËºâÂÖ•Ê®°Âûã
    model = L2CS_MobileNetV3()
    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        model.to(device)
        model.eval()
        print("‚úÖ Student Model Loaded!")
    except FileNotFoundError:
        print(f"‚ùå Error: Êâæ‰∏çÂà∞ {MODEL_PATH}")
        return

    # 2. Ê∫ñÂÇô Haar Cascade (Âèñ‰ª£ MediaPipe)
    face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
    face_cascade = cv2.CascadeClassifier(face_cascade_path)
    if face_cascade.empty():
        print("‚ùå Error: ÁÑ°Ê≥ïËºâÂÖ• OpenCV Haar CascadeÔºÅ")
        return

    # 3. È†êËôïÁêÜ
    transform = transforms.Compose([
        transforms.Resize((INPUT_SIZE, INPUT_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    idx_tensor = torch.FloatTensor([idx for idx in range(90)]).to(device)
    cap = cv2.VideoCapture(0)
    
    # Ë®àÁÆó FPS Áî®
    prev_time = 0
    
    print("üì∑ Demo Started! (Student Model - No MediaPipe)")

    with torch.no_grad():
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            # Èè°ÂÉèÁøªËΩâ
            frame = cv2.flip(frame, 1)
            h, w, _ = frame.shape
            
            # ËΩâÁÅ∞ÈöéÁµ¶ Haar ‰ΩøÁî®
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # ÂÅµÊ∏¨‰∫∫Ëáâ
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
            
            if len(faces) > 0:
                # ÊâæÊúÄÂ§ßÁöÑËáâ
                faces = sorted(faces, key=lambda x: x[2]*x[3], reverse=True)
                x, y, w_face, h_face = faces[0]
                
                # Êì¥Â§ßË£ÅÂàá (Ë∑üË®ìÁ∑¥ÊôÇ‰øùÊåÅ‰∏ÄËá¥ÁöÑ Padding)
                k = 0.5 
                # (Ê≥®ÊÑèÔºöÈÄôË£°Ë¶ÅÂ∞èÂøÉ‰∏çË¶ÅÂàáÂá∫ÈÇäÁïå)
                x_min = max(0, x - int(w_face * k))
                y_min = max(0, y - int(h_face * k))
                x_max = min(w, x + w_face + int(w_face * k)) # ‰øÆÊ≠£ÂØ¨Â∫¶ÁÆóÊ≥ï
                y_max = min(h, y + h_face + int(h_face * k)) # ‰øÆÊ≠£È´òÂ∫¶ÁÆóÊ≥ï
                
                face_img = frame[y_min:y_max, x_min:x_max]
                
                if face_img.size > 0:
                    # ËΩâ PIL
                    from PIL import Image
                    img_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))
                    
                    # Êé®Ë´ñ
                    img_tensor = transform(img_pil).unsqueeze(0).to(device)
                    pitch_out, yaw_out = model(img_tensor)
                    
                    # Ëß£Á¢º
                    pitch_pred = softmax_temperature(pitch_out, 1)
                    yaw_pred = softmax_temperature(yaw_out, 1)
                    
                    pitch_deg = torch.sum(pitch_pred * idx_tensor, 1) * 4 - 180
                    yaw_deg = torch.sum(yaw_pred * idx_tensor, 1) * 4 - 180
                    
                    pitch_rad = pitch_deg[0].item() * np.pi / 180
                    yaw_rad = yaw_deg[0].item() * np.pi / 180
                    
                    # ‰º∞ÁÆóÈºªÂ∞ñ‰ΩçÁΩÆ (Ëáâ‰∏≠ÂøÉÂÜçÁ®çÂæÆ‰∏ãÈù¢‰∏ÄÈªû)
                    nose_x = x + w_face / 2
                    nose_y = y + h_face * 0.6 
                    
                    draw_gaze(frame, pitch_rad, yaw_rad, nose_x, nose_y, w_face)
                    
                    # Áï´Ê°ÜÊ°Ü
                    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
                    
                    # È°ØÁ§∫Êï∏ÂÄº
                    text = f"P: {pitch_rad:.2f} Y: {yaw_rad:.2f}"
                    cv2.putText(frame, text, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

            # È°ØÁ§∫ FPS
            curr_time = time.time()
            fps = 1 / (curr_time - prev_time)
            prev_time = curr_time
            cv2.putText(frame, f"FPS: {int(fps)}", (w - 120, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            cv2.putText(frame, "Student (MobileNet)", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            cv2.imshow('Student Demo', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'): break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()