import onnxruntime as ort
import cv2
import numpy as np
import time
from l2cs import Pipeline
import torch

# ================= âš™ï¸ è¨­å®š =================
ONNX_MODEL_PATH = 'models/litegaze_student_fp32.onnx'
TEACHER_PATH = 'models/L2CSNet_gaze360.pkl' 
# ==========================================

# æ¨¡æ“¬è¢å¹•è§£æåº¦
SCREEN_WIDTH = 1280
SCREEN_HEIGHT = 720

# ç†±åœ–åƒæ•¸
HEATMAP_DECAY_RATE = 0.95 # æ¯å¹€ç†±åœ–è¡°æ¸›é€Ÿåº¦
HEATMAP_BRIGHTNESS = 25  # æ¯å€‹æ–°è¦–ç·šé»çš„äº®åº¦
HEATMAP_RADIUS = 30      # æ¯å€‹æ–°è¦–ç·šé»çš„åŠå¾‘

def compute_gaze_np(logits):
    exp_logits = np.exp(logits - np.max(logits))
    probs = exp_logits / np.sum(exp_logits)
    idx = np.arange(90)
    gaze = np.sum(probs * idx) * 4 - 180
    return gaze

# å…¨å±€è®Šé‡ï¼Œç”¨æ–¼ç†±åœ–
heatmap_data = np.zeros((SCREEN_HEIGHT, SCREEN_WIDTH), dtype=np.float32)

def main():
    # 1. å„ªåŒ– ONNX Session è¨­å®š
    opts = ort.SessionOptions()
    opts.intra_op_num_threads = 4
    sess = ort.InferenceSession(ONNX_MODEL_PATH, sess_options=opts, providers=['CPUExecutionProvider'])
    input_name = sess.get_inputs()[0].name
    
    # 2. åˆå§‹åŒ–åµæ¸¬å™¨
    print("ğŸ‘€ å•Ÿå‹• GPU äººè‡‰åµæ¸¬å™¨...")
    detector = Pipeline(weights=TEACHER_PATH, arch='ResNet50', device=torch.device('cuda'))

    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) 
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    print("\nğŸš€ ç†±åœ– Demo å•Ÿå‹•ï¼æŒ‰ä¸‹ 'q' é€€å‡ºã€‚")
    
    fps_time = time.time()
    frame_count = 0
    
    bbox = None 

    while True:
        ret, frame = cap.read()
        if not ret: break

        frame_count += 1
        if time.time() - fps_time > 1.0:
            fps = frame_count
            frame_count = 0
            fps_time = time.time()

        # æ¯ 2 å¹€åµæ¸¬ä¸€æ¬¡è‡‰éƒ¨
        if frame_count % 2 == 0 or bbox is None:
            try:
                results = detector.step(frame)
                if results.bboxes is not None and len(results.bboxes) > 0:
                    bbox = results.bboxes[0]
            except: pass

        gaze_x_screen, gaze_y_screen = None, None

        if bbox is not None:
            x_min, y_min, x_max, y_max = map(int, bbox[:4])
            h, w, _ = frame.shape
            x_min, y_min, x_max, y_max = max(0, x_min), max(0, y_min), min(w, x_max), min(h, y_max)
            
            face_img = frame[y_min:y_max, x_min:x_max]
            
            if face_img.size > 0:
                # æ¨ç†é è™•ç†
                img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
                img = cv2.resize(img, (224, 224))
                img = img.astype(np.float32) / 255.0
                img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
                img = img.transpose(2, 0, 1)[np.newaxis, ...]

                # è¦–ç·šæ¨ç†
                outputs = sess.run(None, {input_name: img.astype(np.float32)})
                pitch = compute_gaze_np(outputs[0][0])
                yaw = compute_gaze_np(outputs[1][0])

                # ğŸ”¥ ä¿®æ­£ï¼šå‚ç›´åç½®ï¼Œè®“ä½ çœ¼ç›å¾€ä¸Šçœ‹æ™‚èƒ½æº–ç¢ºåæ‡‰
                pitch = pitch + 8.0 

                # å°‡è¦–ç·šè§’åº¦è½‰æ›ç‚ºè¢å¹•ä¸Šçš„åº§æ¨™ (é€™éœ€è¦ä¸€äº›ç¶“é©—æ³•å‰‡çš„æ˜ å°„)
                # é€™è£¡å‡è¨­ä½ çš„é ­åŸºæœ¬æ­£å°è¢å¹•ï¼Œä¸”è¢å¹•ç´„åœ¨å‰æ–¹ 60 å…¬åˆ†è™•
                # é€™å€‹è½‰æ›éœ€è¦æ ¹æ“šä½ çš„å¯¦éš›ä½¿ç”¨æƒ…å¢ƒå¾®èª¿ï¼
                # ç°¡åŒ–æ˜ å°„ï¼špitch å’Œ yaw åœ¨ -180 åˆ° 180 åº¦ä¹‹é–“
                # æˆ‘å€‘å‡è¨­ -45 ~ +45 åº¦æ˜¯è¢å¹•ç¯„åœ
                
                # å°‡ pitch/yaw æ˜ å°„åˆ° 0~1 ä¹‹é–“
                # å‡è¨­è¢å¹•æ°´å¹³è¦–è§’ç´„ 60 åº¦ï¼Œå‚ç›´ç´„ 40 åº¦
                norm_x = (yaw + 30) / 60 # å°‡ yaw æ˜ å°„åˆ° 0~1
                norm_y = (pitch + 20) / 40 # å°‡ pitch æ˜ å°„åˆ° 0~1

                gaze_x_screen = int(np.clip(norm_x * SCREEN_WIDTH, 0, SCREEN_WIDTH - 1))
                gaze_y_screen = int(np.clip(norm_y * SCREEN_HEIGHT, 0, SCREEN_HEIGHT - 1))

                # æ›´æ–° Webcam å½±åƒä¸Šçš„ç®­é ­ (å¯é¸ï¼Œç”¨æ–¼æ¯”å°)
                cx, cy = (x_min + x_max) // 2, (y_min + y_max) // 2
                dx = -100 * np.sin(yaw * np.pi / 180)
                dy = -100 * np.sin(pitch * np.pi / 180)
                cv2.arrowedLine(frame, (cx, cy), (int(cx + dx), int(cy + dy)), (0, 255, 0), 3)
                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
                cv2.putText(frame, f"P:{pitch:.0f} Y:{yaw:.0f}", 
                            (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # ç†±åœ–è™•ç†
        global heatmap_data
        heatmap_data *= HEATMAP_DECAY_RATE # ç†±åœ–è¡°æ¸›
        
        if gaze_x_screen is not None and gaze_y_screen is not None:
            # å¢åŠ æ–°çš„ç†±é»
            cv2.circle(heatmap_data, (gaze_x_screen, gaze_y_screen), HEATMAP_RADIUS, HEATMAP_BRIGHTNESS, -1)
        
        # å°‡ç†±åœ–æ•¸æ“šè½‰æ›ç‚ºå½©è‰²åœ–åƒ
        heatmap_display = np.uint8(np.clip(heatmap_data * (255 / HEATMAP_BRIGHTNESS), 0, 255))
        heatmap_colored = cv2.applyColorMap(heatmap_display, cv2.COLORMAP_JET)

        # é¡¯ç¤º FPS
        cv2.putText(frame, f"FPS: {fps}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # é¡¯ç¤º Webcam ç•«é¢
        cv2.imshow("Webcam Gaze Demo", frame)
        # é¡¯ç¤ºæ¨¡æ“¬è¢å¹•ç†±åœ–
        cv2.imshow("Simulated Screen Heatmap", heatmap_colored)
        
        if cv2.waitKey(1) & 0xFF == ord('q'): break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()