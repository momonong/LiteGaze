import torch
import torch.nn as nn
from torchvision import models
import os

# ================= âš™ï¸ è¨­å®š =================
STUDENT_PATH = 'models/student_mobilenet_3people_9k.pth'
QUANTIZED_PATH = 'models/student_mobilenet_quantized.pth'
# ==========================================

class L2CS_MobileNetV3(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_MobileNetV3, self).__init__()
        self.backbone = models.mobilenet_v3_large(weights=None)
        in_features = self.backbone.classifier[3].in_features
        self.backbone.classifier[3] = nn.Linear(in_features, num_bins * 2)
    def forward(self, x):
        x = self.backbone(x)
        return x[:, :90], x[:, 90:]

def main():
    print(f"ğŸ“¥ è¼‰å…¥ FP32 æ¨¡å‹: {STUDENT_PATH}")
    model = L2CS_MobileNetV3()
    model.load_state_dict(torch.load(STUDENT_PATH, map_location='cpu')) # é‡åŒ–è¦åœ¨ CPU ä¸Šåš
    model.eval()

    print("ğŸ”„ æ­£åœ¨é€²è¡Œå‹•æ…‹é‡åŒ– (Dynamic Quantization)...")
    
    # é‡å° Linear å’Œ LSTM/RNN å±¤é€²è¡Œ int8 é‡åŒ– (MobileNetV3 ä¸»è¦æ˜¯ Convï¼Œä½†åœ¨ CPU ä¸Š PyTorch ä¹Ÿèƒ½å„ªåŒ–)
    # æ³¨æ„ï¼šPyTorch çš„ Dynamic Quantization ä¸»è¦å° Linear æœ‰æ•ˆã€‚
    # å¦‚æœè¦å° Conv é‡åŒ–ï¼Œé€šå¸¸éœ€è¦ Static Quantization (QAT)ï¼Œæ¯”è¼ƒè¤‡é›œã€‚
    # é€™è£¡æˆ‘å€‘å…ˆåšç°¡å–®ç‰ˆï¼Œçœ‹çœ‹èƒ½å£“å¤šå°‘ã€‚
    quantized_model = torch.quantization.quantize_dynamic(
        model, 
        {nn.Linear},  # æŒ‡å®šé‡åŒ– Linear å±¤
        dtype=torch.qint8
    )
    
    print(f"ğŸ’¾ å„²å­˜é‡åŒ–æ¨¡å‹: {QUANTIZED_PATH}")
    torch.save(quantized_model.state_dict(), QUANTIZED_PATH)
    
    # æ¯”è¼ƒå¤§å°
    size_fp32 = os.path.getsize(STUDENT_PATH) / 1024**2
    size_int8 = os.path.getsize(QUANTIZED_PATH) / 1024**2
    
    print(f"\nğŸ“Š å¤§å°æ¯”è¼ƒ:")
    print(f"FP32 Model: {size_fp32:.2f} MB")
    print(f"INT8 Model: {size_int8:.2f} MB")
    print(f"ğŸ‘‰ å£“ç¸®ç‡: {size_fp32/size_int8:.1f}x")

if __name__ == "__main__":
    main()