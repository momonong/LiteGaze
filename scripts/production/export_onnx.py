import torch
import torch.nn as nn
from torchvision import models
import onnx
import os
import shutil

# ================= âš™ï¸ è¨­å®š =================
STUDENT_PATH = 'models/student_mobilenet_3people_9k.pth'
ONNX_SAVE_PATH = 'models/litegaze_student_fp32.onnx'
DEVICE = torch.device('cpu') 
# ==========================================

class L2CS_MobileNetV3(nn.Module):
    def __init__(self, num_bins=90):
        super(L2CS_MobileNetV3, self).__init__()
        self.backbone = models.mobilenet_v3_large(weights=None)
        in_features = self.backbone.classifier[3].in_features
        self.backbone.classifier[3] = nn.Linear(in_features, num_bins * 2)
    def forward(self, x):
        x = self.backbone(x)
        return x[:, :90], x[:, 90:]

def main():
    print(f"ğŸ“¥ è¼‰å…¥ PyTorch æ¨¡å‹: {STUDENT_PATH}")
    model = L2CS_MobileNetV3()
    try:
        model.load_state_dict(torch.load(STUDENT_PATH, map_location=DEVICE))
    except Exception as e:
        print(f"âŒ è¼‰å…¥å¤±æ•—: {e}")
        return
    model.eval()

    dummy_input = torch.randn(1, 3, 224, 224, device=DEVICE)

    print(f"ğŸ”„ å˜—è©¦å°å‡º ONNX (å¼·åˆ¶ Legacy æ¨¡å¼)...")
    
    # åˆªé™¤èˆŠæª”æ¡ˆä»¥å…èª¤åˆ¤
    if os.path.exists(ONNX_SAVE_PATH):
        os.remove(ONNX_SAVE_PATH)

    try:
        # ğŸ”¥ å˜—è©¦æ–¹æ¡ˆ A: é¡¯å¼å‚³å…¥ dynamo=False
        print("ğŸ‘‰ æ–¹æ¡ˆ A: å˜—è©¦å‚³å…¥ dynamo=False åƒæ•¸...")
        torch.onnx.export(
            model,
            dummy_input,
            ONNX_SAVE_PATH,
            export_params=True,
            opset_version=11,          # Legacy æ¨¡å¼æœ€å–œæ­¡ Opset 11
            do_constant_folding=True,
            input_names=['input'],
            output_names=['pitch_logits', 'yaw_logits'],
            dynamic_axes={'input': {0: 'batch_size'},
                          'pitch_logits': {0: 'batch_size'},
                          'yaw_logits': {0: 'batch_size'}},
            dynamo=False  # ğŸš« å¼·åˆ¶é—œé–‰æ–°å¼•æ“
        )
    except TypeError:
        # å¦‚æœ pytorch ç‰ˆæœ¬èˆŠåˆ°ä¸èªè­˜ dynamo åƒæ•¸ï¼Œé‚£å®ƒåŸæœ¬å°±æ˜¯ legacyï¼Œç›´æ¥è·‘
        print("âš ï¸ æ–¹æ¡ˆ A å¤±æ•— (ä¸æ”¯æ´ dynamo åƒæ•¸)ï¼Œè½‰ç‚ºæ–¹æ¡ˆ B (é è¨­å°å‡º)...")
        try:
            torch.onnx.export(
                model,
                dummy_input,
                ONNX_SAVE_PATH,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['pitch_logits', 'yaw_logits'],
                dynamic_axes={'input': {0: 'batch_size'},
                              'pitch_logits': {0: 'batch_size'},
                              'yaw_logits': {0: 'batch_size'}}
            )
        except Exception as e:
            print(f"âŒ æ–¹æ¡ˆ B ä¹Ÿå¤±æ•—: {e}")
            return
    except Exception as e:
        print(f"âŒ å°å‡ºç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
        return

    # é©—æ”¶
    if os.path.exists(ONNX_SAVE_PATH):
        size_mb = os.path.getsize(ONNX_SAVE_PATH) / 1024**2
        print(f"âœ… FP32 ONNX å·²å„²å­˜: {ONNX_SAVE_PATH}")
        print(f"ğŸ“Š æª”æ¡ˆå¤§å°: {size_mb:.2f} MB")
        
        if size_mb < 5.0:
            print("âŒ è­¦å‘Šï¼šæª”æ¡ˆä¾ç„¶æ˜¯ç©ºçš„ï¼è«‹æª¢æŸ¥ä½ çš„ PyTorch å®‰è£æ˜¯å¦æå£ã€‚")
        else:
            print("ğŸ‰ æˆåŠŸï¼é€™æ‰æ˜¯åŒ…å«æ¬Šé‡çš„å®Œæ•´æ¨¡å‹ã€‚")
            print("ğŸ‘‰ ä¸‹ä¸€æ­¥ï¼špython scripts/pretrained/quantize_onnx.py")
    else:
        print("âŒ å°å‡ºå¾Œæ‰¾ä¸åˆ°æª”æ¡ˆï¼")

if __name__ == "__main__":
    main()